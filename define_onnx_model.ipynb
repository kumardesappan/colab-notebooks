{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/d367SphAKT9pPlESnXR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumardesappan/colab-notebooks/blob/main/define_onnx_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8_9TY6nCu6Q"
      },
      "outputs": [],
      "source": [
        "!pip3 install onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Written by refering below\n",
        "# https://leimao.github.io/blog/ONNX-Python-API/\n",
        "\n",
        "import numpy as np\n",
        "import onnx\n",
        "\n",
        "\n",
        "def create_initializer_tensor(\n",
        "        name: str,\n",
        "        tensor_array: np.ndarray,\n",
        "        data_type: onnx.TensorProto = onnx.TensorProto.FLOAT\n",
        ") -> onnx.TensorProto:\n",
        "\n",
        "    # (TensorProto)\n",
        "    initializer_tensor = onnx.helper.make_tensor(\n",
        "        name=name,\n",
        "        data_type=data_type,\n",
        "        dims=tensor_array.shape,\n",
        "        vals=tensor_array.flatten().tolist())\n",
        "\n",
        "    return initializer_tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a dummy convolutional neural network.\n",
        "\n",
        "# IO tensors (ValueInfoProto).\n",
        "model_input_name = \"X\"\n",
        "X = onnx.helper.make_tensor_value_info(model_input_name,\n",
        "                                        onnx.TensorProto.FLOAT,\n",
        "                                        [1, 64, 256, 512])\n",
        "model_output_name = \"Y\"\n",
        "Y = onnx.helper.make_tensor_value_info(model_output_name,\n",
        "                                        onnx.TensorProto.FLOAT,\n",
        "                                        [1, 64, 254, 510])\n",
        "                                        #[None, 64, 256, 512])\n",
        "                                        #[None, 64, 256, 512])\n",
        "\n",
        "kernel_shape = (3, 3)\n",
        "#pads = (1, 1, 1, 1)\n",
        "\n",
        "\n",
        "maxpool_node = onnx.helper.make_node(\n",
        "    name=\"maxpool\",  # Name is optional.\n",
        "    op_type=\"MaxPool\",\n",
        "    inputs=[model_input_name],\n",
        "    outputs=[model_output_name],\n",
        "    kernel_shape = kernel_shape,\n",
        "    #pads = pads,\n",
        "    )\n",
        "\n",
        "\n",
        "# Create the graph (GraphProto)\n",
        "graph_def = onnx.helper.make_graph(\n",
        "    nodes=[maxpool_node],\n",
        "    name=\"MaxPoolTest\",\n",
        "    inputs=[X],  # Graph input\n",
        "    outputs=[Y],  # Graph output\n",
        "    initializer=[],\n",
        ")\n",
        "\n",
        "# Create the model (ModelProto)\n",
        "model_def = onnx.helper.make_model(graph_def, producer_name=\"onnx-example\")\n",
        "model_def.opset_import[0].version = 11\n",
        "\n",
        "model_def = onnx.shape_inference.infer_shapes(model_def)\n",
        "\n",
        "onnx.checker.check_model(model_def)\n",
        "\n",
        "onnx.save(model_def, \"maxpool.onnx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wwteMK2PC6L_"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}